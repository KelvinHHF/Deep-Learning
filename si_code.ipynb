{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(datapath, batch_size=32):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((160, 160)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    dataset = ImageFolder(root=datapath, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFaceNet(torch.nn.Module):\n",
    "    def __init__(self, num_classes=1, freeze_layers=0):\n",
    "        super(CustomFaceNet, self).__init__()\n",
    "        self.model = InceptionResnetV1(pretrained='vggface2')\n",
    "\n",
    "        if freeze_layers > 0:\n",
    "            for param in list(self.model.parameters())[:freeze_layers]:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.fc = torch.nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_facenet(data_loader, num_epochs=5, freeze_layers=0):\n",
    "    model = CustomFaceNet().to(device)\n",
    "\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_images_folder):\n",
    "    model.eval()\n",
    "    results = {}\n",
    "\n",
    "    for img_name in os.listdir(test_images_folder):\n",
    "        img_path = os.path.join(test_images_folder, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((160, 160)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "            predicted_prob = torch.sigmoid(output).item()\n",
    "            results[img_name] = 'M' if predicted_prob > 0.5 else 'F'\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data_folder = '/path/to/dataset/'\n",
    "    test_images_folder = '/path/to/test_images/'\n",
    "\n",
    "    data_loader = load_data(data_folder)\n",
    "\n",
    "    results = {}\n",
    "    for freeze_layers in [0, 5, 10, 15]:\n",
    "        model = finetune_facenet(data_loader, num_epochs=5, freeze_layers=freeze_layers)\n",
    "        results[freeze_layers] = test_model(model, test_images_folder)\n",
    "\n",
    "    with open('results.json', 'w') as json_file:\n",
    "        json.dump(results, json_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(datapath, batch_size=32):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((160, 160)),  # Resize images to a consistent size\n",
    "        transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
    "    ])\n",
    "    dataset = datasets.ImageFolder(root=datapath, transform=transform)  # Automatically labels based on folder names\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)  # Load data in batches, shuffle for randomness\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFaceNet(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(CustomFaceNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)  # First conv layer\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # Second conv layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # Pooling to reduce dimensions\n",
    "        self.fc1 = nn.Linear(64 * 40 * 40, 512)  # Fully connected layer\n",
    "        self.fc2 = nn.Linear(512, num_classes)  # Output layer\n",
    "        self.sigmoid = nn.Sigmoid()  # Activation for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.ReLU()(self.conv1(x)))  # Apply ReLU after first conv and pool\n",
    "        x = self.pool(nn.ReLU()(self.conv2(x)))  # Apply ReLU after second conv and pool\n",
    "        x = x.view(-1, 64 * 40 * 40)  # Flatten the feature map\n",
    "        x = nn.ReLU()(self.fc1(x))  # Apply ReLU after the first fully connected layer\n",
    "        x = self.sigmoid(self.fc2(x))  # Sigmoid for binary output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_facenet(data_loader, num_epochs=5):\n",
    "    model = CustomFaceNet().to(device)  # Initialize the model and move to device\n",
    "    criterion = nn.BCELoss()  # Loss function for binary classification\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Optimizer for training\n",
    "\n",
    "    model.train()  # Set model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to device\n",
    "            optimizer.zero_grad()  # Zero the gradient buffers\n",
    "            outputs = model(images)  # Forward pass\n",
    "            labels = labels.float().unsqueeze(1)  # Reshape labels for loss computation\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backpropagate\n",
    "            optimizer.step()  # Update weights\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_images_folder):\n",
    "    model.eval()\n",
    "    results = {}\n",
    "\n",
    "    for img_name in os.listdir(test_images_folder):\n",
    "        img_path = os.path.join(test_images_folder, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((160, 160)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "            predicted_prob = output.item()\n",
    "            results[img_name] = {\n",
    "                'label': 'M' if predicted_prob > 0.5 else 'F',\n",
    "                'predicted_prob': predicted_prob\n",
    "            }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data_folder = '/path/to/dataset/'  # Path to training data\n",
    "    test_images_folder = '/path/to/test_images/'  # Path to test data\n",
    "\n",
    "    data_loader = load_data(data_folder)  # Load training data\n",
    "\n",
    "    model = finetune_facenet(data_loader, num_epochs=5)  # Train the model\n",
    "    results = test_model(model, test_images_folder)  # Test the model\n",
    "\n",
    "    with open('results_advance.json', 'w') as json_file:\n",
    "        json.dump(results, json_file)  # Save results to a JSON file\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

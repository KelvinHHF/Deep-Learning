{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load datasets\n",
    "def load_data(datapath, batch_size=32):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((160, 160)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    # load dataset from both male and female folders\n",
    "    dataset = ImageFolder(root=datapath, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return loader\n",
    "\n",
    "# Custom model class with forward method\n",
    "class CustomFaceNet(torch.nn.Module):\n",
    "    def __init__(self, num_classes=2, freeze_layers=0):\n",
    "        super(CustomFaceNet, self).__init__()\n",
    "        self.model = InceptionResnetV1(pretrained='vggface2')\n",
    "\n",
    "        # Freeze layers if specified\n",
    "        if freeze_layers > 0:\n",
    "            for param in list(self.model.parameters())[:freeze_layers]:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # Replace the last layer with a new fully connected layer to output two classes (male, female)\n",
    "        self.fc = torch.nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Fine-tune FaceNet\n",
    "def finetune_facenet(data_loader, num_epochs=5, freeze_layers=0):\n",
    "    model = CustomFaceNet().to(device)\n",
    "\n",
    "    # Use CrossEntropyLoss for multi-class classification\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), f'model_freeze_{freeze_layers}.pth')\n",
    "    return model\n",
    "\n",
    "# Test the model and validate predictions\n",
    "def test_model(model, test_images_folder):\n",
    "    model.eval()\n",
    "    results = {}\n",
    "    false_results = []  # To store incorrect predictions\n",
    "\n",
    "    for img_name in os.listdir(test_images_folder):\n",
    "        img_path = os.path.join(test_images_folder, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((160, 160)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        # Ground truth label based on the file name\n",
    "        true_label = 'F' if img_name.startswith('Female') else 'M'\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "            predicted = torch.argmax(output, dim=1).item()\n",
    "            predicted_label = 'M' if predicted == 1 else 'F'\n",
    "\n",
    "        # Record results\n",
    "        results[img_name] = predicted_label\n",
    "\n",
    "        # Check if the prediction was correct\n",
    "        if predicted_label != true_label:\n",
    "            false_results.append({\n",
    "                'image': img_name,\n",
    "                'predicted': predicted_label,\n",
    "                'actual': true_label\n",
    "            })\n",
    "\n",
    "    return results, false_results\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    data_folder = '/content/drive/MyDrive/CUHK/STAT 6207 Deep Learning/train_data'\n",
    "    test_images_folder = '/content/drive/MyDrive/CUHK/STAT 6207 Deep Learning/test_data'\n",
    "\n",
    "    data_loader = load_data(data_folder)\n",
    "\n",
    "    # Fine-tune with different freezing layers\n",
    "    results = {}\n",
    "    all_false_results = {}  # To store false predictions for all freeze_layer settings\n",
    "    for freeze_layers in [0, 5, 10, 15]:\n",
    "        model = finetune_facenet(data_loader, num_epochs=5, freeze_layers=freeze_layers)\n",
    "        # Test and validate the model\n",
    "        predictions, false_results = test_model(model, test_images_folder)\n",
    "        results[freeze_layers] = predictions\n",
    "        all_false_results[freeze_layers] = false_results\n",
    "\n",
    "    # Save results to JSON\n",
    "    with open('Basic_task_FaceNet.json', 'w') as json_file:\n",
    "        json.dump(results, json_file)\n",
    "\n",
    "    # Optionally: You can also save the false predictions or analyze them further\n",
    "    # For now, just keeping it in memory for further analysis\n",
    "    print(\"False predictions have been stored for further analysis.\")\n",
    "    return all_false_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    false_predictions = main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
